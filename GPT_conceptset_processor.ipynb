{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f044edc2-b257-47e1-959b-c10a0f2a46e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import data_utils\n",
    "import conceptset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a4c866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !pip install tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec09e8bc-a9ca-4821-98e6-b1994493da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CLASS_SIM_CUTOFF: Concenpts with cos similarity higher than this to any class will be removed\n",
    "OTHER_SIM_CUTOFF: Concenpts with cos similarity higher than this to another concept will be removed\n",
    "MAX_LEN: max number of characters in a concept\n",
    "\n",
    "PRINT_PROB: what percentage of filtered concepts will be printed\n",
    "\"\"\"\n",
    "\n",
    "CLASS_SIM_CUTOFF = 0.85\n",
    "OTHER_SIM_CUTOFF = 0.9\n",
    "MAX_LEN = 30\n",
    "PRINT_PROB = 1\n",
    "\n",
    "dataset = \"cifar10\"\n",
    "device = \"cpu\"\n",
    "\n",
    "save_name = \"data/concept_sets/{}_gpt4_filtered_new.txt\".format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f98f951-32e8-40af-90d9-a06042126810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDIT these to use the initial concept sets you want\n",
    "\n",
    "with open(\"data/concept_sets/gpt4o/gpt4o_{}_important_new.json\".format(dataset), \"r\") as f:\n",
    "    important_dict = json.load(f)\n",
    "with open(\"data/concept_sets/gpt4o/gpt4o_{}_superclass_new.json\".format(dataset), \"r\") as f:\n",
    "    superclass_dict = json.load(f)\n",
    "with open(\"data/concept_sets/gpt4o/gpt4o_{}_around_new.json\".format(dataset), \"r\") as f:\n",
    "    around_dict = json.load(f)\n",
    "    \n",
    "with open(data_utils.LABEL_FILES[dataset], \"r\") as f:\n",
    "    classes = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da88093-b11f-4273-9599-5c986063e869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "concepts = set()\n",
    "\n",
    "for values in important_dict.values():\n",
    "    concepts.update(set(values))\n",
    "\n",
    "for values in superclass_dict.values():\n",
    "    concepts.update(set(values))\n",
    "    \n",
    "for values in around_dict.values():\n",
    "    concepts.update(set(values))\n",
    "\n",
    "print(len(concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b14c878e-d6f8-47fd-9322-85d14dfbdaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 The most important features for recognizing something as a \"bird\" include:\n",
      "47 **Wheels**: Typically four wheels for movement.\n",
      "62 The most important features for recognizing a \"horse\" include:\n",
      "90 **Large Size**: Ships are typically large, capable of carrying people or cargo over water.\n",
      "75 The most important features for recognizing something as a \"truck\" include:\n",
      "80 **Navigation Equipment**: Tools and instruments used for steering and direction.\n",
      "52 **Four legs**: Long, powerful legs ending in hooves.\n",
      "80 **Gait**: Distinctive walking patterns such as walking, trotting, and galloping.\n",
      "36 A tail (varying in length and shape)\n",
      "73 The most important features for recognizing something as a \"cat\" include:\n",
      "55 **License Plate**: For identification and registration.\n",
      "152 **Anchors**: Used to secure the ship in place when not in motion.These features help differentiate ships from other watercraft like boats or submarines.\n",
      "64 **White Tail**: Some species have a distinctive white underside.\n",
      "73 **Large, muscular body**: Horses have a strong, elongated body structure.\n",
      "50 **Slender Legs**: Adapted for running and jumping.\n",
      "31 In-flight entertainment screens\n",
      "58 **Cargo area**: Often an open bed or enclosed cargo space.\n",
      "74 The most important features for recognizing something as a \"frog\" include:\n",
      "48 **Whiskers**: Long, sensitive hairs on the face.\n",
      "70 **Propulsion System**: Engines, propellers, or sails to move the ship.\n",
      "51 **Head shape**: Long face with large eyes and ears.\n",
      "46 **Bridge**: The control center for navigation.\n",
      "74 The most important features for recognizing something as a \"ship\" include:\n",
      "74 **Engine**: Powerful engine to handle heavy loads and towing capabilities.\n",
      "83 **Wheels**: Typically has four or more wheels, often larger to support heavy loads.\n",
      "45 **Short tail (often with a white underside)**\n",
      "53 **No tail**: Unlike tadpoles, adult frogs lack tails.\n",
      "54 Handle (optional feature for some styles)**Airplane:**\n",
      "34 Barks or makes other vocalizations\n",
      "54 Here are the things most commonly seen around a \"dog\":\n",
      "91 **Superstructure**: Structures above the deck, such as the bridge, where navigation occurs.\n",
      "77 **Propulsion System**: Includes engines and propellers or sails for movement.\n",
      "44 **Steering Wheel**: For directional control.\n",
      "48 **Sharp eyes**: Often with vertical slit pupils.\n",
      "57 To recognize a \"deer,\" look for these important features:\n",
      "79 The most important features for recognizing something as an \"airplane\" include:\n",
      "59 **Moist, smooth skin**: Often green or brown, but can vary.\n",
      "74 Certainly! Here are the most important features for recognizing a \"horse\":\n",
      "65 **Cargo area**: An open bed or enclosed space for carrying goods.\n",
      "55 **Chassis**: A structural frame supporting the vehicle.\n",
      "46 **Large Ears**: Usually upright and attentive.\n",
      "66 **Distinctive fur patterns**: Can vary widely in color and length.\n",
      "74 The most important features for recognizing something as a \"deer\" include:\n",
      "63 Sure! Here are some important features for recognizing a \"dog\":\n",
      "66 Sure! Here’s a list of things most commonly seen around a \"truck\":\n",
      "53 ### Important Features for Recognizing an Automobile:\n",
      "34 **Elongated head with large eyes**\n",
      "98 Distinctive croaking soundThese features help distinguish frogs from other amphibians and animals.\n",
      "63 **Mane and tail**: Hair running along the neck and a long tail.\n",
      "70 **Size**: Generally large and imposing compared to many other animals.\n",
      "37 **Webbed feet**: Useful for swimming.\n",
      "57 **Cab**: A cabin for the driver and sometimes passengers.\n",
      "74 **Large size**: Compared to regular vehicles, trucks are generally larger.\n",
      "37 Distinctive meowing or purring sounds\n",
      "57 **Brown or Tan Fur**: Often with white markings or spots.\n",
      "41 **Antlers (on males, varies by species)**\n",
      "71 **Doors**: Usually two to four, allowing entry and exit for passengers.\n",
      "52 **Large, sturdy frame**: Built to carry heavy loads.\n",
      "93 **Nose**: Small and often moist.These features help in identifying a cat among other animals.\n",
      "73 **Durable construction**: Built with materials suited for heavy-duty use.\n",
      "113 Expressive eyesThese features, along with behaviors such as barking or wagging the tail, can help identify a dog.\n",
      "77 **Multiple wheels**: Typically more than four for stability and load-bearing.\n",
      "72 **Brown or reddish-brown coat (often with white spots in younger deer)**\n",
      "77 **Enclosed Cabin**: A space for passengers, often with seats and a dashboard.\n",
      "55 A tail section with vertical and horizontal stabilizers\n",
      "492 **Most important features for recognizing an \"automobile\":**1. **Wheels**: Typically four, allowing movement on roads.2. **Enclosed Body**: A cabin that can accommodate passengers and/or cargo.3. **Engine**: Provides the power for movement.4. **Steering Mechanism**: Usually a steering wheel for control.5. **Seats**: For driver and passengers.6. **Windows**: To allow visibility and ventilation.7. **Doors**: For entry and exit.8. **Headlights and Taillights**: For visibility and signaling.\n",
      "70 To recognize something as a \"frog,\" consider these important features:\n",
      "74 **Engine**: Usually located at the front or rear, providing power to move.\n",
      "61 **Deck**: The flat surface on top of the hull for operations.\n",
      "47 **Slender, flexible body**: Agile and graceful.\n",
      "90 **Deck**: A flat surface on top of the hull where people can stand or cargo can be stored.\n",
      "78 **Masts or Superstructure**: Vertical structures for sails or other equipment.\n",
      "70 **Chassis**: A strong frame to support the weight of cargo and towing.\n",
      "57 Sure! Here are some things commonly seen around a \"bird\":\n",
      "52 **Hooves**: Cloven and adapted for various terrains.\n",
      "47 **Hull**: The main body that provides buoyancy.\n",
      "174 Typically has a playful or friendly demeanorThese features can vary widely depending on the breed, but they provide a general idea of what to look for when identifying a dog.\n",
      "44 **Lifeboats**: Emergency vessels for safety.\n",
      "34 **Anchor**: Used to moor the ship.\n",
      "77 **Hull**: The main body of the ship, designed to float and provide stability.\n",
      "40 **Long hind legs**: Adapted for jumping.\n",
      "46 **Windows**: Transparent glass for visibility.\n",
      "71 **Tail**: Can vary in length, often used for balance and communication.\n",
      "32 Wings (though not all birds fly)\n",
      "81 To recognize something as a \"dog,\" the most important features typically include:\n",
      "65 **Antlers**: Typically found on males, though not in all species.\n",
      "58 **Retractable claws**: Hidden in the paws when not in use.\n",
      "48 **Bulging eyes**: Positioned on top of the head.\n",
      "67 Sure! Here are the most important features for recognizing a \"cat\":\n",
      "57 **Elevated cab**: Higher seating position for the driver.\n",
      "75 **Axles**: Often multiple axles for better weight distribution and support.\n",
      "34 A wide variety of sizes and breeds\n",
      "52 **Meowing or purring sounds**: Common vocalizations.\n",
      "47 **Pointed ears**: Often upright and triangular.\n",
      "86 Unique vocalizations or callsThese features help distinguish birds from other animals.\n",
      "82 **Lighting**: Headlights, taillights, and indicators for visibility and signaling.\n",
      "53 **Powerful engine**: Designed for towing and hauling.\n",
      "308 211\n"
     ]
    }
   ],
   "source": [
    "concepts = conceptset_utils.remove_too_long(concepts, MAX_LEN, PRINT_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27e7a88-bdd4-49cb-b74d-fd16866eb5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052757555447460db5c16a6151979f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7235c519067944959a8495b7ff7baa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9401e52fc38944c990bfe675fc032be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56d494288ea4c17a15b39064a031bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0354ea7244d643dab03de15b1a8d1455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1328c64666b4bda92e4de01d1bdab14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbc2aca2bd849ffbd37ca248e48814a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e072f90d2b84615874de4c8dae7a792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86705102b9974937a3efe4ae27e8919b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947f5dff9ba14d758cfb8a80030e16b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ff03d0925044558c7d44d9bdaf0176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 335M/335M [00:27<00:00, 12.6MiB/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m concepts \u001b[38;5;241m=\u001b[39m conceptset_utils\u001b[38;5;241m.\u001b[39mfilter_too_similar_to_cls(concepts, classes, CLASS_SIM_CUTOFF, device, PRINT_PROB)\n",
      "File \u001b[0;32m~/Documents/DSC190/Label-free-CBM/conceptset_utils.py:78\u001b[0m, in \u001b[0;36mfilter_too_similar_to_cls\u001b[0;34m(concepts, classes, sim_cutoff, device, print_prob)\u001b[0m\n\u001b[1;32m     76\u001b[0m concept_features_m \u001b[38;5;241m=\u001b[39m mpnet_model\u001b[38;5;241m.\u001b[39mencode(concepts)\n\u001b[1;32m     77\u001b[0m dot_prods_m \u001b[38;5;241m=\u001b[39m class_features_m \u001b[38;5;241m@\u001b[39m concept_features_m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m---> 78\u001b[0m dot_prods_c \u001b[38;5;241m=\u001b[39m _clip_dot_prods(classes, concepts)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#weighted since mpnet has highger variance\u001b[39;00m\n\u001b[1;32m     80\u001b[0m dot_prods \u001b[38;5;241m=\u001b[39m (dot_prods_m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mdot_prods_c)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m\n",
      "File \u001b[0;32m~/Documents/DSC190/Label-free-CBM/conceptset_utils.py:136\u001b[0m, in \u001b[0;36m_clip_dot_prods\u001b[0;34m(list1, list2, device, clip_name, batch_size)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_clip_dot_prods\u001b[39m(list1, list2, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, clip_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mViT-B/16\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturns: numpy array with dot products\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 136\u001b[0m     clip_model, _ \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mload(clip_name, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    137\u001b[0m     text1 \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mtokenize(list1)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    138\u001b[0m     text2 \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mtokenize(list2)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Documents/DSC190/Label-free-CBM/clip/clip.py:139\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, device, jit, download_root)\u001b[0m\n\u001b[1;32m    136\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(opened_file, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jit:\n\u001b[0;32m--> 139\u001b[0m     model \u001b[38;5;241m=\u001b[39m build_model(state_dict \u001b[38;5;129;01mor\u001b[39;00m model\u001b[38;5;241m.\u001b[39mstate_dict())\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(device) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    141\u001b[0m         model\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1160\u001b[0m         device,\n\u001b[1;32m   1161\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1162\u001b[0m         non_blocking,\n\u001b[1;32m   1163\u001b[0m     )\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "concepts = conceptset_utils.filter_too_similar_to_cls(concepts, classes, CLASS_SIM_CUTOFF, device, PRINT_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161dcfb-f9ec-4775-9b80-d8042c4f9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = conceptset_utils.filter_too_similar(concepts, OTHER_SIM_CUTOFF, device, PRINT_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7db95f-3391-4609-b3b4-96f234e972b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_name, \"w\") as f:\n",
    "    f.write(concepts[0])\n",
    "    for concept in concepts[1:]:\n",
    "        f.write(\"\\n\" + concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b4567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
